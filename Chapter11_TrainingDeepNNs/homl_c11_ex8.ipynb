{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x232e3975f90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_val, y_val = X_train_full[-5000:], y_train_full[-5000:]\n",
    "X_train, X_val, X_test = X_train/255., X_val/255., X_test/255.\n",
    "\n",
    "X_train[0]\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_train[0], cmap='binary' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               307300    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32,32, 3]))\n",
    "for index in range(1, 21):\n",
    "    model.add(tf.keras.layers.Dense(100, activation=\"swish\", kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal learning rate with Tensorboard\n",
    "from pathlib import Path\n",
    "      \n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-5)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "run_index = 6 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e23e8f50ceda529c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e23e8f50ceda529c\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_cifar10_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 18s 10ms/step - loss: 1.0112 - accuracy: 0.6431 - val_loss: 1.4308 - val_accuracy: 0.5260\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0068 - accuracy: 0.6452 - val_loss: 1.4338 - val_accuracy: 0.5274\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0041 - accuracy: 0.6459 - val_loss: 1.4399 - val_accuracy: 0.5244\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0018 - accuracy: 0.6474 - val_loss: 1.4424 - val_accuracy: 0.5260\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9992 - accuracy: 0.6484 - val_loss: 1.4446 - val_accuracy: 0.5274\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9967 - accuracy: 0.6492 - val_loss: 1.4469 - val_accuracy: 0.5232\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9943 - accuracy: 0.6486 - val_loss: 1.4451 - val_accuracy: 0.5252\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9922 - accuracy: 0.6506 - val_loss: 1.4507 - val_accuracy: 0.5278\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9898 - accuracy: 0.6506 - val_loss: 1.4546 - val_accuracy: 0.5248\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9872 - accuracy: 0.6522 - val_loss: 1.4525 - val_accuracy: 0.5258\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use optimal learning rate to train model wirh Nadam optimizer and early stopping\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model\", save_best_only=True)\n",
    "\n",
    "run_index = 7 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.0010 - accuracy: 0.6468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 24s 14ms/step - loss: 1.0012 - accuracy: 0.6466 - val_loss: 1.4656 - val_accuracy: 0.5216\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.9912 - accuracy: 0.6504"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9912 - accuracy: 0.6504 - val_loss: 1.4650 - val_accuracy: 0.5256\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9818 - accuracy: 0.6524 - val_loss: 1.4662 - val_accuracy: 0.5256\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9726 - accuracy: 0.6568 - val_loss: 1.4827 - val_accuracy: 0.5248\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9608 - accuracy: 0.6610 - val_loss: 1.4971 - val_accuracy: 0.5238\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9517 - accuracy: 0.6638 - val_loss: 1.5078 - val_accuracy: 0.5208\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9404 - accuracy: 0.6692 - val_loss: 1.5131 - val_accuracy: 0.5162\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9309 - accuracy: 0.6712 - val_loss: 1.5244 - val_accuracy: 0.5190\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9206 - accuracy: 0.6753 - val_loss: 1.5290 - val_accuracy: 0.5182\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9096 - accuracy: 0.6785 - val_loss: 1.5454 - val_accuracy: 0.5160\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8997 - accuracy: 0.6821 - val_loss: 1.5493 - val_accuracy: 0.5188\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8888 - accuracy: 0.6855 - val_loss: 1.5810 - val_accuracy: 0.5162\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8784 - accuracy: 0.6907 - val_loss: 1.5964 - val_accuracy: 0.5154\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8675 - accuracy: 0.6966 - val_loss: 1.6005 - val_accuracy: 0.5146\n",
      "Epoch 15/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8573 - accuracy: 0.6992 - val_loss: 1.6179 - val_accuracy: 0.5146\n",
      "Epoch 16/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8468 - accuracy: 0.7038 - val_loss: 1.6383 - val_accuracy: 0.5092\n",
      "Epoch 17/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8354 - accuracy: 0.7082 - val_loss: 1.6592 - val_accuracy: 0.5080\n",
      "Epoch 18/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8246 - accuracy: 0.7108 - val_loss: 1.6785 - val_accuracy: 0.5118\n",
      "Epoch 19/30\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8138 - accuracy: 0.7162 - val_loss: 1.6975 - val_accuracy: 0.5038\n",
      "Epoch 20/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8028 - accuracy: 0.7201 - val_loss: 1.7358 - val_accuracy: 0.5048\n",
      "Epoch 21/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7924 - accuracy: 0.7238 - val_loss: 1.7389 - val_accuracy: 0.5068\n",
      "Epoch 22/30\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7796 - accuracy: 0.7299 - val_loss: 1.7555 - val_accuracy: 0.5024\n"
     ]
    }
   ],
   "source": [
    "# Run model\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4650 - accuracy: 0.5256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4649752378463745, 0.525600016117096]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate model on validation set\n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               307200    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 100)              400       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               10000     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 506,210\n",
      "Trainable params: 502,210\n",
      "Non-trainable params: 4,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add batch normalisation to previous model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32,32, 3]))\n",
    "for index in range(1, 21):\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer='he_normal', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('swish'))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find batch normalisation optimal rate with Tensorboard\n",
    "# runs = 1:1e-5, 2:3e-5, 3:5e-5, 4:1e-4, 5:3e-4\n",
    "        \n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=3e-4)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "run_index = 5 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_bn_logs\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1407/1407 [==============================] - 26s 12ms/step - loss: 1.3012 - accuracy: 0.5405 - val_loss: 1.7156 - val_accuracy: 0.4222\n",
      "Epoch 2/15\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2903 - accuracy: 0.5444 - val_loss: 1.9018 - val_accuracy: 0.3862\n",
      "Epoch 3/15\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2636 - accuracy: 0.5560 - val_loss: 1.5384 - val_accuracy: 0.4688\n",
      "Epoch 4/15\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2439 - accuracy: 0.5623 - val_loss: 1.6206 - val_accuracy: 0.4444\n",
      "Epoch 5/15\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2214 - accuracy: 0.5726 - val_loss: 1.6403 - val_accuracy: 0.4384\n",
      "Epoch 6/15\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2112 - accuracy: 0.5744 - val_loss: 1.6423 - val_accuracy: 0.4392\n",
      "Epoch 7/15\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1897 - accuracy: 0.5787 - val_loss: 2.0025 - val_accuracy: 0.3662\n",
      "Epoch 8/15\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1666 - accuracy: 0.5882 - val_loss: 1.6864 - val_accuracy: 0.4366\n",
      "Epoch 9/15\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1465 - accuracy: 0.5976 - val_loss: 1.6599 - val_accuracy: 0.4352\n",
      "Epoch 10/15\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1358 - accuracy: 0.6030 - val_loss: 1.5265 - val_accuracy: 0.4766\n",
      "Epoch 11/15\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1188 - accuracy: 0.6051 - val_loss: 1.5737 - val_accuracy: 0.4616\n",
      "Epoch 12/15\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1046 - accuracy: 0.6102 - val_loss: 1.8949 - val_accuracy: 0.4112\n",
      "Epoch 13/15\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0853 - accuracy: 0.6169 - val_loss: 1.6229 - val_accuracy: 0.4448\n",
      "Epoch 14/15\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0753 - accuracy: 0.6198 - val_loss: 1.4717 - val_accuracy: 0.4988\n",
      "Epoch 15/15\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0646 - accuracy: 0.6233 - val_loss: 1.7567 - val_accuracy: 0.4210\n"
     ]
    }
   ],
   "source": [
    "# Run model\n",
    "history = model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.8467 - accuracy: 0.7020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 34s 18ms/step - loss: 0.8467 - accuracy: 0.7020 - val_loss: 1.4063 - val_accuracy: 0.5348\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8379 - accuracy: 0.7040 - val_loss: 1.4522 - val_accuracy: 0.5282\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8317 - accuracy: 0.7077 - val_loss: 1.4536 - val_accuracy: 0.5232\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8297 - accuracy: 0.7090 - val_loss: 1.4389 - val_accuracy: 0.5298\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8236 - accuracy: 0.7075 - val_loss: 1.4290 - val_accuracy: 0.5336\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8244 - accuracy: 0.7069 - val_loss: 1.4581 - val_accuracy: 0.5272\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8117 - accuracy: 0.7142 - val_loss: 1.4500 - val_accuracy: 0.5286\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8133 - accuracy: 0.7123 - val_loss: 1.4694 - val_accuracy: 0.5260\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 18s 12ms/step - loss: 0.8084 - accuracy: 0.7129 - val_loss: 1.4407 - val_accuracy: 0.5368\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8039 - accuracy: 0.7150 - val_loss: 1.4664 - val_accuracy: 0.5308\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 18s 12ms/step - loss: 0.7963 - accuracy: 0.7189 - val_loss: 1.4788 - val_accuracy: 0.5286\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.7901 - accuracy: 0.7176 - val_loss: 1.4912 - val_accuracy: 0.5242\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.7921 - accuracy: 0.7198 - val_loss: 1.4488 - val_accuracy: 0.5292\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.7882 - accuracy: 0.7197 - val_loss: 1.4500 - val_accuracy: 0.5352\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 18s 12ms/step - loss: 0.7838 - accuracy: 0.7219 - val_loss: 1.4615 - val_accuracy: 0.5322\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.7774 - accuracy: 0.7261 - val_loss: 1.4864 - val_accuracy: 0.5242\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.7696 - accuracy: 0.7267 - val_loss: 1.4975 - val_accuracy: 0.5256\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.7708 - accuracy: 0.7286 - val_loss: 1.5592 - val_accuracy: 0.5198\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.7621 - accuracy: 0.7306 - val_loss: 1.4933 - val_accuracy: 0.5264\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.7718 - accuracy: 0.7269 - val_loss: 1.4786 - val_accuracy: 0.5254\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.7595 - accuracy: 0.7322 - val_loss: 1.5004 - val_accuracy: 0.5260\n"
     ]
    }
   ],
   "source": [
    "# Use optimal learning rate to train previous model with batch normalisation\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "run_index = 7 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_bn_logs\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step - loss: 1.4063 - accuracy: 0.5348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4063448905944824, 0.5347999930381775]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
